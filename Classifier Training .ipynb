{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "#The OS module in Python provides a way of using operating system dependent functionality.\n",
    "\n",
    "from collections import Counter\n",
    "# A Counter is a dict subclass for counting hashable objects. \n",
    "# It is an unordered collection where elements are stored as dictionary keys and their counts are stored as dictionary values.\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB   \n",
    "# used to apply function of naive bayes\n",
    "\n",
    "from sklearn.model_selection import train_test_split as tts \n",
    "# break the whole dataset into 2 segments randomly as training and testing dataset.\n",
    "\n",
    "from sklearn.metrics import accuracy_score   \n",
    "# to calculate accuracy of the classifier\n",
    "\n",
    "import pickle as c\n",
    "# for turning an arbitrary Python object into a series of bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dictionary():\n",
    "    directory = \"emails/\"\n",
    "    files = os.listdir(directory)    # creates a list of all the mails in emails folder\n",
    "    emails = [directory + email for email in files]  # emails/ham or spam name.\n",
    "    words = []  #list of words\n",
    "    length = len(emails)   # calculating length of list()\n",
    "    \n",
    "    for email in emails:  # iterating through each mail in emails list\n",
    "        f = open(email, errors='ignore')   # f is file type variable\n",
    "        blob = f.read()   # blob is string type variable to read each mail in emails list\n",
    "        words += blob.split(\" \")\n",
    "        \n",
    "    # now we have created a list of every word in the emails folder\n",
    "    for i in range(len(words)):     \n",
    "        if not words[i].isalpha(): # if word are not alphabet we replace it with an empty string\n",
    "            words[i] = \"\"\n",
    "\n",
    "    dictionary = Counter(words)  # this is the dictionary of words  : frequency(decreasing order)\n",
    "    del dictionary[\"\"]   # deleting empty strings from the dictionary\n",
    "    return dictionary.most_common(1000)   # returning a list of 1000 key(words)-value(frequency) pairs\n",
    "    # for e.g. [('the', 22003), ('to', 16118)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = make_dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(dictionary):\n",
    "    directory = \"emails/\"\n",
    "    files = os.listdir(directory)\n",
    "    emails = [directory + email for email in files]\n",
    "    feature_set = []    # feature_set list\n",
    "    labels = []         # labels list\n",
    "\n",
    "    for email in emails:\n",
    "        data = []\n",
    "        f = open(email,errors='ignore')\n",
    "        words = f.read().split(' ')\n",
    "        for entry in dictionary:  # iterating dictionary\n",
    "            data.append(words.count(entry[0]))   # here we are appending the frequency of each dictionary key in the word list\n",
    "                      \n",
    "        feature_set.append(data) # is a list of list(each of length 1000 and frequncy of each word of dictionary in that mail)\n",
    "\n",
    "        if \"ham\" in email:  # assigning labels based on the names of the files\n",
    "            labels.append(0)  # appending 0 \n",
    "        if \"spam\" in email:\n",
    "            labels.append(1)  # appending 1 \n",
    "\n",
    "    return feature_set, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, labels = make_dataset(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, labels_train, labels_test = tts(features, labels, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9207729468599034\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(labels_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the training of classifier\n",
    "def save_classifier(clf, name):\n",
    "    with open(name, 'wb') as fp:\n",
    "        c.dump(clf, fp)\n",
    "    print(\"Classifier Training Saved!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Training Saved!!\n"
     ]
    }
   ],
   "source": [
    "save_classifier(clf, \"spam-classifier.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
